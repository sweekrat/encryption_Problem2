{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxZzqq_rREWM",
        "outputId": "14b70c30-7ae6-422c-ab61-dfaef7c0c222"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.10/dist-packages (26.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a1t8hgFQ19G",
        "outputId": "b6b1267a-4951-4f1f-95af-6eca677b0258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file created successfully.\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import random\n",
        "from faker import Faker\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "# Define the number of records\n",
        "num_records = 1000000\n",
        "\n",
        "# Open a file to write\n",
        "with open('sample_data.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"first_name\", \"last_name\", \"address\", \"date_of_birth\"])\n",
        "\n",
        "    # Write the data\n",
        "    for _ in range(num_records):\n",
        "        writer.writerow([fake.first_name(), fake.last_name(), fake.address(), fake.date_of_birth()])\n",
        "\n",
        "print(\"CSV file created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnOxzakLRvX9",
        "outputId": "68d52e7b-bc8a-493a-d2e9-c74db312517f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cryptography"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c34YhuYYUqVn",
        "outputId": "233c6f43-ee6b-411a-89fd-c60cf195e90e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (42.0.8)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cryptography.fernet import Fernet\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "# Generate a key for encryption\n",
        "key = Fernet.generate_key()\n",
        "cipher_suite = Fernet(key)\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"AnonymizeData\").getOrCreate()\n",
        "\n",
        "# Load the data\n",
        "df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \",\").option(\"quote\", '\"').option(\"escape\", '\"').option(\"multiline\", \"true\").load(\"sample_data.csv\")\n",
        "\n",
        "# Define a UDF to encrypt the data\n",
        "def encrypt_data(x):\n",
        "    return cipher_suite.encrypt(x.encode()).decode() if x is not None else None\n",
        "encrypt_udf = udf(encrypt_data, StringType())\n",
        "\n",
        "# Anonymize the columns\n",
        "df = df.withColumn('first_name', encrypt_udf(df['first_name'])) \\\n",
        "       .withColumn('last_name', encrypt_udf(df['last_name'])) \\\n",
        "       .withColumn('address', encrypt_udf(df['address']))\n",
        "\n",
        "# Save the anonymized data\n",
        "df.write.csv('anonymized_large_data.csv', header=True, mode='overwrite')\n",
        "\n",
        "# Save the key to a file\n",
        "with open('key.key', 'wb') as key_file:\n",
        "    key_file.write(key)\n",
        "\n",
        "print(\"data anonymized successfully.\")\n",
        "\n",
        "# Stop the Spark session"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyd8BrerRYr8",
        "outputId": "ef38d307-0dfc-4acd-a188-f2e7833405e2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large data anonymized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from pyspark.sql import SparkSession\n",
        "\n",
        "# spark = SparkSession.builder.appName(\"AnonymizeData\").getOrCreate()\n",
        "\n",
        "# df_valid = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \",\").option(\"quote\", '\"').option(\"escape\", '\"').option(\"multiline\", \"true\").load(\"sample_data.csv\")\n",
        "\n",
        "# # Show the schema and first few rows to verify\n",
        "# df_valid.printSchema()\n",
        "# df_valid.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "Rf1IPUbdkYUF",
        "outputId": "bd84cbd1-3ef6-48f1-9c1f-5bfaebe77b52"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7b707394bfb8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jchO_dsTkLq_",
        "outputId": "2ffa9c79-7903-455f-ab28-1259969e4a3a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+-------------+\n",
            "|          first_name|           last_name|             address|date_of_birth|\n",
            "+--------------------+--------------------+--------------------+-------------+\n",
            "|gAAAAABmjWouR2E_f...|gAAAAABmjWouCDKLI...|gAAAAABmjWouJhTL9...|   1922-03-19|\n",
            "|gAAAAABmjWouWc4zT...|gAAAAABmjWouk6jq0...|gAAAAABmjWouV8t0T...|   1972-11-15|\n",
            "|gAAAAABmjWou-E7n6...|gAAAAABmjWouR2zR2...|gAAAAABmjWoudkkho...|   1948-12-09|\n",
            "|gAAAAABmjWougfhz_...|gAAAAABmjWouUo9z4...|gAAAAABmjWou0Vwgd...|   1974-03-26|\n",
            "|gAAAAABmjWouHUWhg...|gAAAAABmjWoumSAaf...|gAAAAABmjWou--akq...|   1985-04-20|\n",
            "|gAAAAABmjWouznxPt...|gAAAAABmjWou22hUz...|gAAAAABmjWoub6ygH...|   1923-02-05|\n",
            "|gAAAAABmjWouRUTnX...|gAAAAABmjWou4Lrgo...|gAAAAABmjWou490bc...|   1920-10-09|\n",
            "|gAAAAABmjWou6cwwv...|gAAAAABmjWouWcWBQ...|gAAAAABmjWou768l7...|   1931-11-04|\n",
            "|gAAAAABmjWoubqxhF...|gAAAAABmjWouMCeoH...|gAAAAABmjWouJw-tX...|   1922-11-04|\n",
            "|gAAAAABmjWouDgcCi...|gAAAAABmjWouGhXpN...|gAAAAABmjWouvcGtd...|   1949-12-15|\n",
            "|gAAAAABmjWoug_wEU...|gAAAAABmjWouuSCPH...|gAAAAABmjWousHk09...|   1974-09-26|\n",
            "|gAAAAABmjWouFxA6i...|gAAAAABmjWouohbQx...|gAAAAABmjWouLQoQN...|   1981-11-20|\n",
            "|gAAAAABmjWoun0ocw...|gAAAAABmjWougNv4a...|gAAAAABmjWouJO5sD...|   1965-12-29|\n",
            "|gAAAAABmjWouPPpge...|gAAAAABmjWoubbXj9...|gAAAAABmjWoucgBcf...|   2000-02-10|\n",
            "|gAAAAABmjWouos27U...|gAAAAABmjWouqTJC-...|gAAAAABmjWoubAZf7...|   1920-07-31|\n",
            "|gAAAAABmjWou6cOb0...|gAAAAABmjWoujike0...|gAAAAABmjWouSNB8G...|   1967-10-29|\n",
            "|gAAAAABmjWouNVn3-...|gAAAAABmjWouUhQ_a...|gAAAAABmjWouQPj0_...|   2002-11-09|\n",
            "|gAAAAABmjWoulFpYR...|gAAAAABmjWou34T8v...|gAAAAABmjWoucCT88...|   1950-04-17|\n",
            "|gAAAAABmjWou7GL2-...|gAAAAABmjWou_VqQn...|gAAAAABmjWouPOR4S...|   1945-03-23|\n",
            "|gAAAAABmjWouYAbiQ...|gAAAAABmjWouQijfJ...|gAAAAABmjWoujSbXV...|   1937-05-27|\n",
            "+--------------------+--------------------+--------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cryptography.fernet import Fernet\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "# Load the key\n",
        "with open('key.key', 'rb') as key_file:\n",
        "    key = key_file.read()\n",
        "\n",
        "cipher_suite = Fernet(key)\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"DeAnonymizeData\").getOrCreate()\n",
        "\n",
        "# Load the anonymized data\n",
        "df = spark.read.csv('anonymized_large_data.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Define a UDF to decrypt the data\n",
        "def decrypt_data(x):\n",
        "    return cipher_suite.decrypt(x.encode()).decode() if x is not None else None\n",
        "decrypt_udf = udf(decrypt_data, StringType())\n",
        "\n",
        "# De-anonymize the columns\n",
        "df = df.withColumn('first_name', decrypt_udf(df['first_name'])) \\\n",
        "       .withColumn('last_name', decrypt_udf(df['last_name'])) \\\n",
        "       .withColumn('address', decrypt_udf(df['address']))\n",
        "\n",
        "# Save the de-anonymized data\n",
        "df.write.csv('deanonymized_large_data.csv', header=True, mode='overwrite')\n",
        "\n",
        "print(\"Large data de-anonymized successfully.\")\n",
        "\n",
        "# Stop the Spark session\n",
        "# spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caIzi9KaRpBW",
        "outputId": "93a5cf2a-2176-4125-eeeb-10dbb688dfb2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large data de-anonymized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP1kJwBga0dR",
        "outputId": "f81af7ef-4e2e-4f79-f37d-1cb16a9e6ddf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+--------------------+-------------+\n",
            "|first_name| last_name|             address|date_of_birth|\n",
            "+----------+----------+--------------------+-------------+\n",
            "|   Matthew|    Miller|0188 Bennett Way ...|   1922-03-19|\n",
            "|   Rebecca|    Romero|1080 Hall Terrace...|   1972-11-15|\n",
            "|   Charles|     Velez|USS Vasquez\\nFPO ...|   1948-12-09|\n",
            "|     James|     Ortiz|18721 Freeman Vis...|   1974-03-26|\n",
            "|   Colleen|      Ryan|50216 Anna Terrac...|   1985-04-20|\n",
            "|    Robert|     Green|1422 Solis Stream...|   1923-02-05|\n",
            "|    Andrew|     Smith|USNS Juarez\\nFPO ...|   1920-10-09|\n",
            "|  Jennifer|   Webster|9121 Cole Road Ap...|   1931-11-04|\n",
            "|     Haley|     Lopez|895 Jenna Prairie...|   1922-11-04|\n",
            "|      John|    Mercer|4977 Carmen Burgs...|   1949-12-15|\n",
            "|     Sarah|    Garcia|3067 Jones Mills ...|   1974-09-26|\n",
            "|    Edward|   Jackson|52935 Marcia Moun...|   1981-11-20|\n",
            "|     Aaron|    Newman|97220 Price Key\\n...|   1965-12-29|\n",
            "|    Monica|     Myers|6755 Porter Freew...|   2000-02-10|\n",
            "|  Kristina|Harrington|9878 Flores Trace...|   1920-07-31|\n",
            "|    Denise|   English|90178 Ferguson Wa...|   1967-10-29|\n",
            "|   Lindsey|Washington|4162 Melissa Fort...|   2002-11-09|\n",
            "|Jacqueline|      Wood|641 Amber Ville\\n...|   1950-04-17|\n",
            "|      Kyle|     Kline|2593 Wilson Way S...|   1945-03-23|\n",
            "|   Michael|    Oliver|USNS Reyes\\nFPO A...|   1937-05-27|\n",
            "+----------+----------+--------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}